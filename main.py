from fastapi import FastAPI, Request, Query, HTTPException
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.templating import Jinja2Templates
from real_crawler import RealNewsCrawler
import uvicorn
from typing import List, Dict, Optional
import logging
from datetime import datetime, timedelta

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="ê´€ì‹¬ì‚¬ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬")

# í…œí”Œë¦¿ ì„¤ì •
templates = Jinja2Templates(directory="templates")

# í¬ë¡¤ëŸ¬ ì¸ìŠ¤í„´ìŠ¤ (ì‹¤ì œ ì†ŒìŠ¤ ì‚¬ìš©)
news_crawler = RealNewsCrawler()

# ìºì‹œëœ ë‰´ìŠ¤ ë°ì´í„° (ì¹´í…Œê³ ë¦¬ë³„)
cached_news: Dict[str, Dict] = {}  # {category: {'articles': [...], 'cached_at': datetime}}

# ìºì‹œ TTL (5ë¶„)
CACHE_TTL = timedelta(minutes=5)


def is_cache_valid(category: str) -> bool:
    """ìºì‹œê°€ ìœ íš¨í•œì§€ í™•ì¸"""
    if category not in cached_news:
        return False
    
    cached_at = cached_news[category].get('cached_at')
    if not cached_at:
        return False
    
    if isinstance(cached_at, str):
        cached_at = datetime.fromisoformat(cached_at)
    
    return datetime.now() - cached_at < CACHE_TTL


@app.on_event("startup")
async def startup_event():
    """ì•± ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    logger.info("ì•± ì‹œì‘ - ì¹´í…Œê³ ë¦¬ í¬ë¡¤ëŸ¬ ì¤€ë¹„ ì™„ë£Œ")


@app.get("/", response_class=HTMLResponse)
async def home(request: Request, category: Optional[str] = Query(None)):
    """ë©”ì¸ í˜ì´ì§€"""
    categories = news_crawler.get_all_categories()
    
    return templates.TemplateResponse(
        "index.html",
        {
            "request": request,
            "categories": categories,
            "current_category": category
        }
    )


@app.get("/api/categories")
async def get_categories():
    """ì¹´í…Œê³ ë¦¬ ëª©ë¡ API"""
    categories = news_crawler.get_all_categories()
    return {
        "success": True,
        "categories": categories
    }


@app.get("/api/news")
async def get_news(category: Optional[str] = Query(None)):
    """ì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤ API (ê°œì„ )"""
    if not category:
        return JSONResponse(
            status_code=400,
            content={
                "success": False,
                "message": "ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.",
                "categories": category_crawler.get_all_categories()
            }
        )
    
    if category not in news_crawler.CATEGORIES:
        return JSONResponse(
            status_code=404,
            content={
                "success": False,
                "message": f"ì•Œ ìˆ˜ ì—†ëŠ” ì¹´í…Œê³ ë¦¬: {category}"
            }
        )
    
    # ìºì‹œ í™•ì¸
    if is_cache_valid(category):
        logger.info(f"[API] {category} ì¹´í…Œê³ ë¦¬ ìºì‹œ ì‚¬ìš©")
        return {
            "success": True,
            "category": category,
            "category_name": news_crawler.CATEGORIES[category]['name'],
            "count": len(cached_news[category]['articles']),
            "articles": cached_news[category]['articles']
        }
    
    # í¬ë¡¤ë§ ìˆ˜í–‰
    try:
        logger.info(f"[API] {category} ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§ ì‹œì‘...")
        logger.info(f"[API] ì¹´í…Œê³ ë¦¬ ì •ë³´: {news_crawler.CATEGORIES.get(category, 'NOT FOUND')}")
        
        articles = news_crawler.crawl_category(category)
        logger.info(f"[API] í¬ë¡¤ë§ ê²°ê³¼: {len(articles)}ê°œ ê¸°ì‚¬")
        
        # ì‘ë‹µ í˜•ì‹ í†µì¼ (ì‹¤ì œ ë°ì´í„°ë§Œ ë°˜í™˜, ìƒ˜í”Œ ë°ì´í„° ì—†ìŒ)
        formatted_articles = []
        for i, article in enumerate(articles):
            url = article.get('url', '')
            # ë”ë¯¸ URL í•„í„°ë§
            if 'example.com' in url or not url or url.startswith('https://example'):
                logger.warning(f"[API] ë”ë¯¸ URL í•„í„°ë§: {url}")
                continue
            
            formatted_articles.append({
                "id": f"{category}_{i}",
                "title": article.get('title', ''),
                "url": url,
                "source": article.get('source', ''),
                "publishedAt": article.get('publishedAt', datetime.now().isoformat()),
                "imageUrl": article.get('imageUrl', '') or '',
                "summary": article.get('summary', '') or ''
            })
        
        logger.info(f"[API] í¬ë§·íŒ… ì™„ë£Œ: {len(formatted_articles)}ê°œ (ë”ë¯¸ í•„í„°ë§ í›„)")
        
        # ìºì‹œ ì €ì¥
        cached_news[category] = {
            'articles': formatted_articles,
            'cached_at': datetime.now()
        }
        
        return {
            "success": True,
            "category": category,
            "category_name": news_crawler.CATEGORIES[category]['name'],
            "count": len(formatted_articles),
            "articles": formatted_articles
        }
    
    except Exception as e:
        logger.error(f"[API] {category} ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}", exc_info=True)
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "message": f"ë‰´ìŠ¤ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "articles": []
            }
        )


@app.get("/api/news/refresh")
async def refresh_news(category: Optional[str] = Query(None)):
    """ë‰´ìŠ¤ ìƒˆë¡œê³ ì¹¨"""
    if not category:
        return JSONResponse(
            status_code=400,
            content={
                "success": False,
                "message": "ì¹´í…Œê³ ë¦¬ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."
            }
        )
    
    if category not in news_crawler.CATEGORIES:
        return JSONResponse(
            status_code=404,
            content={
                "success": False,
                "message": f"ì•Œ ìˆ˜ ì—†ëŠ” ì¹´í…Œê³ ë¦¬: {category}"
            }
        )
    
    try:
        logger.info(f"[API] {category} ì¹´í…Œê³ ë¦¬ ë‰´ìŠ¤ ìƒˆë¡œê³ ì¹¨ ìš”ì²­...")
        
        # ìºì‹œ ë¬´íš¨í™”
        if category in cached_news:
            del cached_news[category]
        
        # í¬ë¡¤ë§ ìˆ˜í–‰
        articles = news_crawler.crawl_category(category)
        
        # ì‘ë‹µ í˜•ì‹ í†µì¼ (ë”ë¯¸ URL í•„í„°ë§)
        formatted_articles = []
        for i, article in enumerate(articles):
            url = article.get('url', '')
            if 'example.com' in url or not url or url.startswith('https://example'):
                continue
            
            formatted_articles.append({
                "id": f"{category}_{i}",
                "title": article.get('title', ''),
                "url": url,
                "source": article.get('source', ''),
                "publishedAt": article.get('publishedAt', datetime.now().isoformat()),
                "imageUrl": article.get('imageUrl', '') or '',
                "summary": article.get('summary', '') or ''
            })
        
        # ìºì‹œ ì €ì¥
        cached_news[category] = {
            'articles': formatted_articles,
            'cached_at': datetime.now()
        }
        
        return {
            "success": True,
            "message": "ë‰´ìŠ¤ê°€ ìƒˆë¡œê³ ì¹¨ë˜ì—ˆìŠµë‹ˆë‹¤.",
            "category": category,
            "category_name": news_crawler.CATEGORIES[category]['name'],
            "count": len(formatted_articles)
        }
    
    except Exception as e:
        logger.error(f"{category} ì¹´í…Œê³ ë¦¬ ìƒˆë¡œê³ ì¹¨ ì˜¤ë¥˜: {e}")
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "message": f"ìƒˆë¡œê³ ì¹¨ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            }
        )


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    total_news = sum(len(data.get('articles', [])) for data in cached_news.values())
    return {
        "status": "healthy",
        "cached_categories": list(cached_news.keys()),
        "total_news_count": total_news,
        "cache_ttl_minutes": CACHE_TTL.total_seconds() / 60
    }


if __name__ == "__main__":
    print("\n" + "="*60)
    print("ğŸ¯ ê´€ì‹¬ì‚¬ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ ì‹œì‘")
    print("="*60)
    print("\nğŸ“ ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ ë‹¤ìŒ ì£¼ì†Œë¡œ ì ‘ì†í•˜ì„¸ìš”:")
    print("   ğŸ‘‰ http://localhost:8000")
    print("\nğŸ“¡ API ì—”ë“œí¬ì¸íŠ¸:")
    print("   - GET /api/categories     : ì¹´í…Œê³ ë¦¬ ëª©ë¡ ì¡°íšŒ")
    print("   - GET /api/news?category= : ì¹´í…Œê³ ë¦¬ë³„ ë‰´ìŠ¤ ì¡°íšŒ")
    print("   - GET /api/news/refresh?category= : ë‰´ìŠ¤ ìƒˆë¡œê³ ì¹¨")
    print("\nğŸ“‚ ì§€ì› ì¹´í…Œê³ ë¦¬:")
    categories = RealNewsCrawler().get_all_categories()
    for key, name in categories.items():
        print(f"   - {name} ({key})")
    print("\nâš ï¸  ë„¤ì´ë²„ API ì‚¬ìš© ì‹œ í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìš”:")
    print("   export NAVER_CLIENT_ID='your_client_id'")
    print("   export NAVER_CLIENT_SECRET='your_client_secret'")
    print("\nâ¹ï¸  ì¢…ë£Œí•˜ë ¤ë©´ Ctrl+Cë¥¼ ëˆ„ë¥´ì„¸ìš”\n")
    print("="*60 + "\n")
    
    uvicorn.run(app, host="0.0.0.0", port=8000, log_level="info")
